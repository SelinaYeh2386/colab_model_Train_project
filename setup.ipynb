{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0257f8a9",
   "metadata": {},
   "source": [
    "# Colab / VS Codeï¼ˆColab Kernelï¼‰åˆå§‹åŒ–æµç¨‹ï¼šè®“ä½ èƒ½æˆåŠŸåŸ·è¡Œ train.py\n",
    "\n",
    "é€™ä»½ Notebook æœƒå¾é›¶é–‹å§‹ï¼š\n",
    "1.ï¼ˆå¯é¸ï¼‰ç¢ºèªä½ åœ¨ Colab GPU Runtime\n",
    "2. è¼¸å…¥ GitHub Tokenï¼ˆè‹¥ repo ç§æœ‰æ‰éœ€è¦ï¼‰\n",
    "3. è¼¸å…¥ GitHub Repository é€£çµ\n",
    "4. Clone/Pull å°ˆæ¡ˆ\n",
    "5. å®‰è£ä¾è³´\n",
    "6. åŸ·è¡Œ `train.py`\n",
    "\n",
    "## é‡è¦æé†’ï¼ˆè«‹å‹™å¿…çœ‹ï¼‰\n",
    "- **ä¸è¦æŠŠ GitHub Token æ˜ç¢¼å¯«é€² Notebook**ï¼Œç”¨äº’å‹•è¼¸å…¥å³å¯ã€‚\n",
    "- å¦‚æœ repo æ˜¯ publicï¼Œå¯ä»¥æŠŠ Token ç•™ç©ºã€‚\n",
    "- åœ¨ Notebook è«‹ç›¡é‡ä½¿ç”¨ `sys.executable -m pip` å®‰è£å¥—ä»¶ï¼Œé¿å… `pip` å’Œ `python` æŒ‡åˆ°ä¸åŒç’°å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b316743",
   "metadata": {},
   "source": [
    "## 1)ï¼ˆå¯é¸ï¼‰ç¢ºèªä½ æ˜¯ä¸æ˜¯ Colab Runtimeï¼ˆä»¥åŠ GPU æ˜¯å¦å¯ç”¨ï¼‰\n",
    "\n",
    "- è‹¥ä½ æ˜¯åœ¨ VS Code é€é `google.colab` extension é€£åˆ° Colab Kernelï¼šé€™äº›æª¢æŸ¥æœƒé¡¯ç¤º Colab çš„è·¯å¾‘ï¼ˆå¸¸è¦‹æ˜¯ `/content`ï¼‰ã€‚\n",
    "- è‹¥ä½ æƒ³ç”¨ GPUï¼šè«‹åœ¨ Colab é‚£é‚ŠæŠŠ Runtime è¨­å®šæˆ GPUï¼ˆä¸åŒé€£ç·šæ–¹å¼ UI ä½ç½®å¯èƒ½ä¸åŒï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32d1e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
      "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "Executable: /usr/bin/python3\n",
      "CWD: /content/colab_model_Train_project\n",
      "\n",
      "[GPU check] nvidia-smi:\n",
      "(not available)\n",
      "\n",
      "[PyTorch check]\n",
      "torch: 2.9.0+cpu\n",
      "torch.version.cuda: None\n",
      "CUDA available: False\n",
      "CUDA device count: 0\n",
      "\n",
      "çµè«–ï¼šç›®å‰æ˜¯ CPU è¨“ç·´ç’°å¢ƒï¼ˆCUDA ä¸å¯ç”¨ï¼‰ã€‚\n",
      "åŸå› é€šå¸¸æ˜¯ä»¥ä¸‹å…¶ä¸­ä¹‹ä¸€ï¼š\n",
      "  A) ä½ é€£åˆ°çš„æ˜¯ã€ŒCPU runtimeã€ï¼šnvidia-smi ä¸å­˜åœ¨ï¼ˆä½ å‰›å‰›çœ‹åˆ°çš„ç‹€æ³ï¼‰\n",
      "  B) runtime æœ‰ GPUï¼Œä½†ä½ è£åˆ°çš„æ˜¯ CPU-only torchï¼ˆtorch ç‰ˆæœ¬æœƒå‡ºç¾ +cpuï¼Œä¸” torch.version.cuda æœƒæ˜¯ Noneï¼‰\n",
      "\n",
      "è¦ä½¿ç”¨ GPUï¼šéœ€è¦åœ¨ Colab ç«¯æŠŠ runtime åˆ‡æˆ GPUï¼Œä¸¦é‡æ–°é€£ç·š/é‡å•Ÿå¾Œå†è·‘ä¸€æ¬¡æ­¤æª¢æŸ¥ã€‚\n",
      "æ³¨æ„ï¼šä¿®æ”¹é€™æ®µæª¢æŸ¥ç¨‹å¼ç¢¼æœ¬èº«ï¼Œä¸æœƒæŠŠ CPU runtime è®Šæˆ GPU runtimeã€‚\n"
     ]
    }
   ],
   "source": [
    "import os, sys, platform, subprocess\n",
    "print('Platform:', platform.platform())\n",
    "print('Python:', sys.version)\n",
    "print('Executable:', sys.executable)\n",
    "print('CWD:', os.getcwd())\n",
    "\n",
    "# 1) å…ˆç”¨ç³»çµ±å±¤ç´šçš„æ–¹å¼æª¢æŸ¥ï¼šé€™å° runtime æœ‰æ²’æœ‰ NVIDIA GPU / é©…å‹•å·¥å…·\n",
    "print('\\n[GPU check] nvidia-smi:')\n",
    "try:\n",
    "    out = subprocess.run(['bash', '-lc', 'command -v nvidia-smi && nvidia-smi -L'], capture_output=True, text=True)\n",
    "    if out.returncode == 0 and out.stdout.strip():\n",
    "        print(out.stdout.strip())\n",
    "    else:\n",
    "        # å¸¸è¦‹æƒ…æ³ï¼šCPU runtime æœƒé¡¯ç¤ºæ‰¾ä¸åˆ° nvidia-smi\n",
    "        msg = (out.stderr or out.stdout or '').strip()\n",
    "        print('(not available)')\n",
    "        if msg:\n",
    "            print(msg)\n",
    "except Exception as e:\n",
    "    print('(not available)', e)\n",
    "\n",
    "# 2) å†ç”¨ PyTorch æª¢æŸ¥ï¼štorch æ˜¯å¦ç‚º CUDA ç‰ˆæœ¬ã€ä»¥åŠ CUDA æ˜¯å¦å¯ç”¨\n",
    "print('\\n[PyTorch check]')\n",
    "try:\n",
    "    import torch\n",
    "    print('torch:', torch.__version__)\n",
    "    print('torch.version.cuda:', torch.version.cuda)\n",
    "    print('CUDA available:', torch.cuda.is_available())\n",
    "    print('CUDA device count:', torch.cuda.device_count())\n",
    "    if torch.cuda.is_available():\n",
    "        print('GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print('\\nçµè«–ï¼šç›®å‰æ˜¯ CPU è¨“ç·´ç’°å¢ƒï¼ˆCUDA ä¸å¯ç”¨ï¼‰ã€‚')\n",
    "        print('åŸå› é€šå¸¸æ˜¯ä»¥ä¸‹å…¶ä¸­ä¹‹ä¸€ï¼š')\n",
    "        print('  A) ä½ é€£åˆ°çš„æ˜¯ã€ŒCPU runtimeã€ï¼šnvidia-smi ä¸å­˜åœ¨ï¼ˆä½ å‰›å‰›çœ‹åˆ°çš„ç‹€æ³ï¼‰')\n",
    "        print('  B) runtime æœ‰ GPUï¼Œä½†ä½ è£åˆ°çš„æ˜¯ CPU-only torchï¼ˆtorch ç‰ˆæœ¬æœƒå‡ºç¾ +cpuï¼Œä¸” torch.version.cuda æœƒæ˜¯ Noneï¼‰')\n",
    "        print('\\nè¦ä½¿ç”¨ GPUï¼šéœ€è¦åœ¨ Colab ç«¯æŠŠ runtime åˆ‡æˆ GPUï¼Œä¸¦é‡æ–°é€£ç·š/é‡å•Ÿå¾Œå†è·‘ä¸€æ¬¡æ­¤æª¢æŸ¥ã€‚')\n",
    "        print('æ³¨æ„ï¼šä¿®æ”¹é€™æ®µæª¢æŸ¥ç¨‹å¼ç¢¼æœ¬èº«ï¼Œä¸æœƒæŠŠ CPU runtime è®Šæˆ GPU runtimeã€‚')\n",
    "except Exception as e:\n",
    "    print('torch not available yet (OK):', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b4c70",
   "metadata": {},
   "source": [
    "## 2) è¼¸å…¥ GitHub Token èˆ‡ Repository è³‡è¨Š\n",
    "\n",
    "- Repo æ˜¯ **private**ï¼šéœ€è¦ Token æ‰èƒ½ clone/pull\n",
    "- Repo æ˜¯ **public**ï¼šToken å¯ç•™ç©ºï¼ˆç›´æ¥æŒ‰ Enterï¼‰\n",
    "\n",
    "é€™è£¡ç”¨ `GIT_USERNAME` + `GIT_REPO` ä¾†çµ„å‡º GitHub é€£çµï¼š\n",
    "- `https://github.com/<username>/<repo>.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0f0172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo folder: /content/colab_model_Train_project\n"
     ]
    }
   ],
   "source": [
    "# å»ºè­°ä¸è¦æŠŠ GitHub Token æ˜ç¢¼å¯«é€² notebookï¼ˆå®¹æ˜“å¤–æµï¼‰\n",
    "# 1) å…ˆåœ¨ç³»çµ±ç’°å¢ƒè®Šæ•¸è¨­å®š GIT_TOKENï¼Œæˆ– 2) åŸ·è¡Œæ™‚å†è²¼ä¸Š\n",
    "import os\n",
    "import getpass\n",
    "from pathlib import Path\n",
    "\n",
    "# Public repoï¼šå¯ç›´æ¥æŒ‰ Enter è·³é Token\n",
    "GIT_TOKEN = os.getenv(\"GIT_TOKEN\") or getpass.getpass(\"GitHub Tokenï¼ˆrepo public å¯ç›´æ¥æŒ‰ Enter è·³éï¼Œè¼¸å…¥ä¸æœƒé¡¯ç¤ºï¼‰: \")\n",
    "\n",
    "# ä½ çš„ GitHub å¸³è™Ÿèˆ‡ repo åç¨±ï¼ˆå¯ä¾éœ€è¦ä¿®æ”¹ï¼‰\n",
    "GIT_USERNAME = \"SelinaYeh2386\"\n",
    "GIT_REPO = \"colab_model_Train_project\"\n",
    "\n",
    "# repo è³‡æ–™å¤¾è·¯å¾‘ï¼ˆæœƒ clone åˆ°ç›®å‰å·¥ä½œç›®éŒ„åº•ä¸‹ï¼‰\n",
    "repo_dir = Path.cwd() / GIT_REPO\n",
    "print(\"Repo folder:\", repo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12b31d",
   "metadata": {},
   "source": [
    "## 3) Cloneï¼ˆè‹¥å·²å­˜åœ¨å‰‡ Pullï¼‰\n",
    "\n",
    "é€™æ®µæœƒï¼š\n",
    "- å¦‚æœè³‡æ–™å¤¾ä¸å­˜åœ¨ï¼šclone\n",
    "- å¦‚æœè³‡æ–™å¤¾å·²å­˜åœ¨ï¼špull\n",
    "\n",
    "> å°æé†’ï¼šä½¿ç”¨ Token clone æ™‚ï¼ŒToken å¯èƒ½æœƒè¢«å¯«é€² `.git/config` çš„ remote URLï¼ˆæœ‰å¤–æ´©é¢¨éšªï¼‰ã€‚é€™è£¡æœƒç›¡é‡é¿å…æŠŠ Token å°åœ¨è¼¸å‡ºä¸Šï¼Œä½†ä½ ä»æ‡‰è©²ä½¿ç”¨ fine-grained tokenã€æœ€å°æ¬Šé™ã€ç”¨å®Œå¯æ’¤éŠ·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf7ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already exists, pulling latest: /content/colab_model_Train_project\n",
      "Done. Repo path: /content/colab_model_Train_project\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "import subprocess\n",
    "\n",
    "# çµ„å‡º repo URLï¼ˆä¸å« tokenï¼‰\n",
    "REPO_URL = f\"https://github.com/{GIT_USERNAME}/{GIT_REPO}.git\"\n",
    "\n",
    "# éœ€è¦ tokenï¼ˆprivate repoï¼‰æ™‚ï¼Œæ‰åœ¨ clone éšæ®µç”¨å¸¶ token çš„ URL\n",
    "if GIT_TOKEN:\n",
    "    CLONE_URL = f\"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPO}.git\"\n",
    "else:\n",
    "    CLONE_URL = REPO_URL\n",
    "\n",
    "if not repo_dir.exists():\n",
    "    print(\"Cloning into:\", repo_dir)\n",
    "    # æ¥ä¸‹ä¾†åŸ·è¡Œ clone æŒ‡ä»¤ï¼ˆæ³¨æ„ï¼šä¸æœƒæŠŠ token å€¼å°å‡ºä¾†ï¼‰\n",
    "    subprocess.run([\"git\", \"clone\", CLONE_URL, str(repo_dir)], check=True)\n",
    "\n",
    "    # é‡è¦ï¼šæŠŠ origin URL æ”¹å›ä¸å« tokenï¼Œé¿å… token è¢«å¯«é€² .git/config\n",
    "    subprocess.run([\"git\", \"-C\", str(repo_dir), \"remote\", \"set-url\", \"origin\", REPO_URL], check=True)\n",
    "else:\n",
    "    print(\"Repo already exists, pulling latest:\", repo_dir)\n",
    "    subprocess.run([\"git\", \"-C\", str(repo_dir), \"rev-parse\", \"--is-inside-work-tree\"], check=True, capture_output=True, text=True)\n",
    "    subprocess.run([\"git\", \"-C\", str(repo_dir), \"pull\"], check=True)\n",
    "\n",
    "print(\"Done. Repo path:\", repo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a099c3f8",
   "metadata": {},
   "source": [
    "## 4) é€²å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œç¢ºèª train.py / requirements.txt\n",
    "\n",
    "å¦‚æœä½ è·‘åˆ°é€™ä¸€æ­¥ä»æ‰¾ä¸åˆ° `train.py` æˆ– `requirements.txt`ï¼Œä»£è¡¨ repo å¯èƒ½å¤šåŒ…äº†ä¸€å±¤è³‡æ–™å¤¾ï¼›ä½ å¯ä»¥ç”¨ `find` å»æ‰¾æª”æ¡ˆä½ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35a3fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /content/colab_model_Train_project\n",
      "Top-level files: ['.git', 'README.md', 'data.yaml', 'datasets', 'models', 'requirements.txt', 'train.py', 'yolov8n.pt']\n",
      "train.py exists: True\n",
      "requirements.txt exists: True\n",
      "data.yaml exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "print('CWD:', Path.cwd())\n",
    "print('Top-level files:', [p.name for p in sorted(Path.cwd().iterdir())][:50])\n",
    "\n",
    "print('train.py exists:', Path('train.py').exists())\n",
    "print('requirements.txt exists:', Path('requirements.txt').exists())\n",
    "print('data.yaml exists:', Path('data.yaml').exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ad35fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train.py\n"
     ]
    }
   ],
   "source": [
    "# è‹¥ train.py ä¸åœ¨é€™å±¤ï¼Œç”¨ find æ‰¾å®ƒ\n",
    "!find . -maxdepth 4 -name train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8e2995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# è‹¥ requirements.txt ä¸åœ¨é€™å±¤ï¼Œç”¨ find æ‰¾å®ƒ\n",
    "!find . -maxdepth 4 -name requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6051b9",
   "metadata": {},
   "source": [
    "## 5) å®‰è£ä¾è³´ï¼ˆå»ºè­°ç”¨ sys.executable -m pipï¼‰\n",
    "\n",
    "é€™ä¸€æ­¥æœƒè§£æ±ºå¸¸è¦‹éŒ¯èª¤ï¼š\n",
    "- `ModuleNotFoundError: No module named 'ultralytics'`\n",
    "\n",
    "å¦‚æœä½ çš„ `requirements.txt` ä¸åœ¨ç›®å‰è³‡æ–™å¤¾ï¼Œè«‹å…ˆ `cd` åˆ°åŒ…å«å®ƒçš„è³‡æ–™å¤¾å†å®‰è£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc6677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python: /usr/bin/python3\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print('Using Python:', sys.executable)\n",
    "req = Path('requirements.txt')\n",
    "if not req.exists():\n",
    "    raise FileNotFoundError('requirements.txt ä¸åœ¨ç›®å‰ç›®éŒ„ï¼Œè«‹å…ˆ cd åˆ°æ­£ç¢ºä½ç½®')\n",
    "\n",
    "!{sys.executable} -m pip install -U pip\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9a5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics version: 8.4.6\n"
     ]
    }
   ],
   "source": [
    "# é©—è­‰ ultralytics æ˜¯å¦å¯ç”¨\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "print('ultralytics version:', ultralytics.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81432747",
   "metadata": {},
   "source": [
    "## 6) åŸ·è¡Œè¨“ç·´\n",
    "\n",
    "- å»ºè­°åŒæ¨£ç”¨ `sys.executable` ä¾†åŸ·è¡Œ `train.py`ï¼Œç¢ºä¿è·Ÿå‰›å‰›å®‰è£å¥—ä»¶çš„æ˜¯åŒä¸€å€‹ç’°å¢ƒã€‚\n",
    "- è¨“ç·´çµæœé è¨­æœƒè¼¸å‡ºåˆ° `models/` åº•ä¸‹ï¼ˆä¾‹å¦‚ `models/my_exp/weights/best.pt`ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0aabe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.6 ğŸš€ Python-3.12.12 torch-2.9.0+cpu CPU (Intel Xeon CPU @ 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco8.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=my_exp6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=models, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/colab_model_Train_project/models/my_exp6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, 16, None, [64, 128, 256]]\n",
      "Model summary: 130 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1414.5Â±282.7 MB/s, size: 50.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/colab_model_Train_project/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 838.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1085.9Â±245.8 MB/s, size: 54.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/colab_model_Train_project/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 621.4Kit/s 0.0s\n",
      "Plotting labels to /content/colab_model_Train_project/models/my_exp6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.000119, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 0 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/content/colab_model_Train_project/models/my_exp6\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/5         0G      1.436      3.694      1.765         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.4s/it 8.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
      "                   all          4         17      0.781      0.833      0.875      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/5         0G      1.434      3.915      1.763         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5s/it 7.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
      "                   all          4         17      0.802       0.75      0.875      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        3/5         0G      1.179      2.864      1.372         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.2s/it 7.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
      "                   all          4         17      0.783       0.75      0.875      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        4/5         0G      1.113      2.704      1.393         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.1s/it 6.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
      "                   all          4         17      0.704       0.75      0.875      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        5/5         0G      1.043       2.76      1.233         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0s/it 7.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
      "                   all          4         17      0.683       0.75      0.875      0.599\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from /content/colab_model_Train_project/models/my_exp6/weights/last.pt, 6.5MB\n",
      "Optimizer stripped from /content/colab_model_Train_project/models/my_exp6/weights/best.pt, 6.5MB\n",
      "\n",
      "Validating /content/colab_model_Train_project/models/my_exp6/weights/best.pt...\n",
      "Ultralytics 8.4.6 ğŸš€ Python-3.12.12 torch-2.9.0+cpu CPU (Intel Xeon CPU @ 2.20GHz)\n",
      "Model summary (fused): 73 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 0.9s\n",
      "                   all          4         17       0.78      0.833      0.875      0.646\n",
      "                person          3         10      0.942        0.5      0.526      0.276\n",
      "                   dog          1          1      0.639          1      0.995      0.697\n",
      "                 horse          1          2      0.893          1      0.995       0.73\n",
      "              elephant          1          2      0.847        0.5      0.745      0.282\n",
      "              umbrella          1          1      0.611          1      0.995      0.995\n",
      "          potted plant          1          1      0.751          1      0.995      0.895\n",
      "Speed: 2.1ms preprocess, 211.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1m/content/colab_model_Train_project/models/my_exp6\u001b[0m\n",
      "--- è¨“ç·´å®Œæˆï¼æ¬Šé‡å·²å„²å­˜æ–¼ models/my_exp/weights/ ---\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aecba989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/my_exp5/weights/last.pt\n",
      "./models/my_exp5/weights/best.pt\n",
      "./models/my_exp2/weights/last.pt\n",
      "./models/my_exp2/weights/best.pt\n",
      "./models/my_exp3/weights/last.pt\n",
      "./models/my_exp3/weights/best.pt\n",
      "./models/my_exp4/weights/last.pt\n",
      "./models/my_exp4/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# æ‰¾è¼¸å‡ºæ¬Šé‡æª”\n",
    "!find . -maxdepth 6 -name best.pt -o -name last.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9858a",
   "metadata": {},
   "source": [
    "## 6.5) ä¿å­˜ / ä¸‹è¼‰è¨“ç·´è¼¸å‡ºï¼ˆbest.pt / last.ptï¼‰\n",
    "\n",
    "ä½ å‰›å‰›çœ‹åˆ°çš„ `models/**/weights/*.pt` **æ˜¯å­˜åœ¨ Colab runtime çš„æª”æ¡ˆ**ï¼Œä¸æœƒè‡ªå‹•è·‘å›ä½ æœ¬æ©Ÿçš„ VS Code å°ˆæ¡ˆè³‡æ–™å¤¾ã€‚\n",
    "\n",
    "- æƒ³æŠŠæ¬Šé‡å¸¶å›æœ¬æ©Ÿï¼šå»ºè­° **æ‰“åŒ…æˆ zip å¾Œä¸‹è¼‰**ï¼ˆæˆ–æ”¹ç”¨é›²ç«¯ç¡¬ç¢Ÿ / Release / LFSï¼‰ã€‚\n",
    "- **ä¸å»ºè­°**æŠŠå¤§å‹æ¬Šé‡ç›´æ¥ `git commit` é€² repoï¼ˆæœƒå¾ˆè‚¥ã€ä¹Ÿå¯èƒ½è¶…é GitHub é™åˆ¶ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "# æ”¶é›†æ‰€æœ‰æ¬Šé‡æª”ï¼ˆä¾ä½ çš„ train.py è¨­å®šï¼Œé è¨­æœƒåœ¨ models/**/weights/ åº•ä¸‹ï¼‰\n",
    "weight_files = sorted(Path('models').glob('**/weights/*.pt'))\n",
    "print('Found weight files:', len(weight_files))\n",
    "for p in weight_files[-10:]:\n",
    "    print(' -', p)\n",
    "\n",
    "if not weight_files:\n",
    "    raise FileNotFoundError('æ‰¾ä¸åˆ° models/**/weights/*.ptï¼›è«‹å…ˆå®Œæˆè¨“ç·´æˆ–ç¢ºèªè¼¸å‡ºè·¯å¾‘')\n",
    "\n",
    "# ä»¥ã€Œæœ€å¾Œä¿®æ”¹æ™‚é–“ã€æ¨æ¸¬æœ€æ–°ä¸€æ¬¡è¨“ç·´çš„ run è³‡æ–™å¤¾\n",
    "latest_weight = max(weight_files, key=lambda p: p.stat().st_mtime)\n",
    "run_dir = latest_weight.parent.parent  # models/<exp_name>/weights/<file>.pt -> models/<exp_name>\n",
    "print('Latest run dir:', run_dir)\n",
    "\n",
    "# æ‰“åŒ…ï¼šweights/*.pt + å¸¸è¦‹çš„çµæœ/è¨­å®šæª”ï¼ˆå­˜åœ¨æ‰åŠ å…¥ï¼‰\n",
    "candidates = []\n",
    "candidates += sorted((run_dir / 'weights').glob('*.pt'))\n",
    "for extra in ['args.yaml', 'results.csv', 'results.png']:\n",
    "    p = run_dir / extra\n",
    "    if p.exists():\n",
    "        candidates.append(p)\n",
    "\n",
    "zip_name = Path(f\"{run_dir.name}_export_{time.strftime('%Y%m%d_%H%M%S')}.zip\")\n",
    "with zipfile.ZipFile(zip_name, 'w', compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for p in candidates:\n",
    "        # å£“åˆ°åŒä¸€å€‹æ ¹ç›®éŒ„ï¼š<exp_name>/...\n",
    "        arcname = Path(run_dir.name) / p.relative_to(run_dir)\n",
    "        z.write(p, arcname=str(arcname))\n",
    "\n",
    "print('Created:', zip_name)\n",
    "print('Absolute path:', zip_name.resolve())\n",
    "print('Size (MB):', round(zip_name.stat().st_size / 1024 / 1024, 2))\n",
    "\n",
    "# è‹¥åœ¨ Colab ç’°å¢ƒï¼šå˜—è©¦è§¸ç™¼ç€è¦½å™¨ä¸‹è¼‰\n",
    "try:\n",
    "    from google.colab import files  # type: ignore\n",
    "    files.download(str(zip_name))\n",
    "except Exception as e:\n",
    "    print('Auto-download not available in this environment (OK):', e)\n",
    "    print('ä½ å¯ä»¥ç”¨å·¦å´æª”æ¡ˆç€è¦½å™¨æ‰‹å‹•ä¸‹è¼‰è©² zipï¼Œæˆ–æŠŠå®ƒç§»åˆ°ä½ è‡ªå·±çš„é›²ç«¯ä½ç½®ã€‚')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da210786",
   "metadata": {},
   "source": [
    "## 7)ï¼ˆå¯é¸ï¼‰æŠŠè®Šæ›´ commit + push å› GitHubï¼ˆå»ºè­°åªæ¨ç¨‹å¼ç¢¼/è¨­å®šï¼‰\n",
    "\n",
    "å¦‚æœä½ åœ¨ Colab ç«¯æœ‰æ”¹åˆ°ç¨‹å¼ç¢¼ï¼ˆä¾‹å¦‚ `train.py`ã€`requirements.txt`ã€notebookï¼‰ï¼Œå¯ä»¥åœ¨é€™ä¸€æ­¥æŠŠè®Šæ›´ **commit + push** å› GitHubã€‚\n",
    "\n",
    "> æ³¨æ„ï¼šä¸å»ºè­°æŠŠå¤§å‹æ¨¡å‹æ¬Šé‡ï¼ˆä¾‹å¦‚ `models/**/weights/*.pt`ï¼‰ç›´æ¥ commit é€² GitHubï¼ˆæª”æ¡ˆå¾ˆå¤§ã€ä¹Ÿå®¹æ˜“æŠŠ repo æåˆ°å¾ˆæ…¢ï¼‰ã€‚é€šå¸¸æœƒç”¨ GitHub Releaseã€é›²ç«¯ç¡¬ç¢Ÿã€æˆ– Git LFS ä¾†ä¿å­˜æ¬Šé‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bfeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import subprocess\n",
    "\n",
    "# éœ€è¦ push æ™‚ï¼Œå»ºè­°ä½¿ç”¨ tokenï¼ˆprivate repo å¿…å¡«ï¼›public repo ä¹Ÿå¯èƒ½éœ€è¦ï¼‰\n",
    "if not GIT_TOKEN:\n",
    "    GIT_TOKEN = os.getenv(\"GIT_TOKEN\") or getpass.getpass(\"GitHub Tokenï¼ˆç”¨æ–¼ git pushï¼Œè¼¸å…¥ä¸æœƒé¡¯ç¤ºï¼‰: \")\n",
    "\n",
    "# è¨­å®š git èº«åˆ†ï¼ˆè‹¥å·²è¨­å®šæœƒç•¥éï¼‰\n",
    "subprocess.run([\"git\", \"config\", \"--global\", \"user.name\"], capture_output=True, text=True)\n",
    "name = subprocess.run([\"git\", \"config\", \"--global\", \"user.name\"], capture_output=True, text=True).stdout.strip()\n",
    "email = subprocess.run([\"git\", \"config\", \"--global\", \"user.email\"], capture_output=True, text=True).stdout.strip()\n",
    "if not name:\n",
    "    subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", GIT_USERNAME], check=True)\n",
    "if not email:\n",
    "    subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", f\"{GIT_USERNAME}@users.noreply.github.com\"], check=True)\n",
    "\n",
    "# æš«æ™‚æŠŠ origin è¨­æˆå« token çš„ URLï¼ˆpush å®Œæœƒæ”¹å›ä¸å« tokenï¼‰\n",
    "AUTH_URL = f\"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPO}.git\"\n",
    "subprocess.run([\"git\", \"remote\", \"set-url\", \"origin\", AUTH_URL], check=True)\n",
    "\n",
    "# é¡¯ç¤ºç‹€æ…‹\n",
    "print(subprocess.run([\"git\", \"status\"], capture_output=True, text=True).stdout)\n",
    "\n",
    "# åªè¦ä½ ç¢ºèªè¦æ¨å› GitHubï¼Œå°± add/commit/push\n",
    "subprocess.run([\"git\", \"add\", \"-A\"], check=True)\n",
    "msg = input(\"Commit messageï¼ˆä¾‹å¦‚: update notebook / codeï¼‰: \").strip() or \"Update from Colab\"\n",
    "commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "print(commit.stdout or commit.stderr)\n",
    "\n",
    "# å¦‚æœæ²’æœ‰è®Šæ›´å¯æäº¤ï¼Œgit commit æœƒå›å‚³é 0ï¼›ä»å¯å˜—è©¦ pushï¼ˆé€šå¸¸æœƒé¡¯ç¤º up-to-dateï¼‰\n",
    "push = subprocess.run([\"git\", \"push\"], capture_output=True, text=True)\n",
    "print(push.stdout or push.stderr)\n",
    "\n",
    "# æŠŠ origin æ”¹å›ä¸å« tokenï¼Œé¿å… token ç•™åœ¨ .git/config\n",
    "subprocess.run([\"git\", \"remote\", \"set-url\", \"origin\", REPO_URL], check=True)\n",
    "print(\"origin reset to:\", REPO_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535ef8e",
   "metadata": {},
   "source": [
    "æŸ¥è©¢Colab VM Repoä¸‹çš„æª”æ¡ˆæ¶æ§‹æŒ‡ä»¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0079c817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/colab_model_Train_project\n",
      "/content/colab_model_Train_project/models\n",
      "/content/colab_model_Train_project/models/my_exp5\n",
      "/content/colab_model_Train_project/models/my_exp2\n",
      "/content/colab_model_Train_project/models/my_exp3\n",
      "/content/colab_model_Train_project/models/my_exp\n",
      "/content/colab_model_Train_project/models/my_exp4\n",
      "/content/colab_model_Train_project/.git\n",
      "/content/colab_model_Train_project/.git/objects\n",
      "/content/colab_model_Train_project/.git/branches\n",
      "/content/colab_model_Train_project/.git/refs\n",
      "/content/colab_model_Train_project/.git/logs\n",
      "/content/colab_model_Train_project/.git/info\n",
      "/content/colab_model_Train_project/.git/hooks\n",
      "/content/colab_model_Train_project/datasets\n",
      "/content/colab_model_Train_project/datasets/coco8\n"
     ]
    }
   ],
   "source": [
    "!find {repo_dir} -maxdepth 2 -type d -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cfe0dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9acddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch; print(torch.__version__); print(torch.cuda.is_available()); print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42fb9f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author identity unknown\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'root@5c9642094d92.(none)')\n"
     ]
    }
   ],
   "source": [
    "!git commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c968f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global user.email \"Selina.yeh@insyde.com\"\n",
    "!git config --global user.name \"SelinaYeh2386\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4b430b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mmodels/my_exp4/\u001b[m\n",
      "\t\u001b[31mmodels/my_exp5/\u001b[m\n",
      "\t\u001b[31mmodels/my_exp6/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fa96451",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd5711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<odel_Train_project/.git/COMMIT_EDITMSG\" 60L, 2568B\u001b[2;1Hâ–½\u001b[6n\u001b[2;1H  \u001b[3;1H\u001bPzz\u001b\\\u001b[0%m\u001b[6n\u001b[3;1H           \u001b[1;1H\u001b[>c\u001b]10;?\u0007\u001b]11;?\u0007\u001b[2;1H\u001b[34m# Please enter the commit message for your changes. Lines starting\u001b[m\u001b[2;67H\u001b[K\u001b[3;1H\u001b[34m# with '#' will be ignored, and an empty message aborts the commit.\u001b[m\u001b[3;68H\u001b[K\u001b[4;1H\u001b[34m#\n",
      "# On branch \u001b[m\u001b[35mmain\u001b[m\n",
      "\u001b[34m# Your branch is up to date with '\u001b[m\u001b[35morigin/main\u001b[m\u001b[34m'.\n",
      "#\n",
      "# \u001b[m\u001b[35mChanges to be committed:\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/BoxF1_curve.png\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/BoxPR_curve.png\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/BoxP_curve.png\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/BoxR_curve.png\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/args.yaml\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/confusion_matrix.png\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/confusion_matrix_normalized.png\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/labels.jpg\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/results.csv\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/results.png\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/train_batch0.jpg\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/train_batch1.jpg\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/train_batch2.jpg\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/val_batch0_labels.jpg\u001b[m\n",
      "\u001b[34m#       \u001b[m\u001b[32mnew file\u001b[m\u001b[34m: \u001b[m\u001b[31m  models/my_exp4/val_batch0_pred.jpg\u001b[m\u001b[24;63H1,0-1\u001b[9CTop\u001b[1;1H\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!git commit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
